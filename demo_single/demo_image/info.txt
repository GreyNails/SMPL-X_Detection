[10/11 23:40:30.643]: git:
  sha: 01da7cd617913b224541fd4ead97456500da5226, status: has uncommited changes, branch: main

[10/11 23:40:30.645]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/11 23:40:30.660]: Full config saved to demo_single/demo_image/config_args_all.json
[10/11 23:40:30.660]: rank: 0
[10/11 23:40:30.660]: local_rank: None
[10/11 23:40:30.661]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/11 23:40:43.378]: number of params:73540770
[10/11 23:40:43.397]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/11 23:40:43.423]: Creating dataset...
[10/11 23:43:13.456]: git:
  sha: 01da7cd617913b224541fd4ead97456500da5226, status: has uncommited changes, branch: main

[10/11 23:43:13.458]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/11 23:43:13.472]: Full config saved to demo_single/demo_image/config_args_all.json
[10/11 23:43:13.472]: rank: 0
[10/11 23:43:13.472]: local_rank: None
[10/11 23:43:13.473]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/11 23:43:26.693]: number of params:73540770
[10/11 23:43:26.713]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/11 23:43:26.739]: Creating dataset...
