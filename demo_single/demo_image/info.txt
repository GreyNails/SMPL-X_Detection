[10/03 15:25:56.582]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 15:25:56.584]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 15:25:56.598]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 15:25:56.598]: rank: 0
[10/03 15:25:56.598]: local_rank: None
[10/03 15:25:56.599]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 15:26:24.399]: number of params:73540770
[10/03 15:26:24.419]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 15:26:24.445]: Creating dataset...
[10/03 15:33:36.255]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 15:33:36.257]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 15:33:36.270]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 15:33:36.271]: rank: 0
[10/03 15:33:36.271]: local_rank: None
[10/03 15:33:36.272]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 15:33:48.320]: number of params:73540770
[10/03 15:33:48.339]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 15:33:48.365]: Creating dataset...
[10/03 15:35:29.200]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 15:35:29.202]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 15:35:29.215]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 15:35:29.215]: rank: 0
[10/03 15:35:29.215]: local_rank: None
[10/03 15:35:29.217]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 15:35:41.700]: number of params:73540770
[10/03 15:35:41.720]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 15:35:41.746]: Creating dataset...
[10/03 15:39:59.347]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 15:39:59.349]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 15:39:59.363]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 15:39:59.363]: rank: 0
[10/03 15:39:59.364]: local_rank: None
[10/03 15:39:59.365]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 15:40:11.469]: number of params:73540770
[10/03 15:40:11.489]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 15:40:11.515]: Creating dataset...
[10/03 15:43:13.434]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 15:43:13.436]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 15:43:13.449]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 15:43:13.449]: rank: 0
[10/03 15:43:13.449]: local_rank: None
[10/03 15:43:13.450]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 15:43:25.586]: number of params:73540770
[10/03 15:43:25.605]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 15:43:25.632]: Creating dataset...
[10/03 15:46:09.512]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 15:46:09.514]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 15:46:09.529]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 15:46:09.529]: rank: 0
[10/03 15:46:09.530]: local_rank: None
[10/03 15:46:09.531]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 15:46:22.376]: number of params:73540770
[10/03 15:46:22.396]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 15:46:22.424]: Creating dataset...
[10/03 15:51:14.654]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 15:51:14.656]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 15:51:14.670]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 15:51:14.670]: rank: 0
[10/03 15:51:14.671]: local_rank: None
[10/03 15:51:14.672]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 15:51:27.338]: number of params:73540770
[10/03 15:51:27.358]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 15:51:27.384]: Creating dataset...
[10/03 15:59:23.437]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 15:59:23.439]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 15:59:23.452]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 15:59:23.452]: rank: 0
[10/03 15:59:23.453]: local_rank: None
[10/03 15:59:23.454]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 15:59:35.913]: number of params:73540770
[10/03 15:59:35.934]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 15:59:35.961]: Creating dataset...
[10/03 16:01:54.646]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:01:54.648]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:01:54.662]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:01:54.662]: rank: 0
[10/03 16:01:54.663]: local_rank: None
[10/03 16:01:54.664]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:02:06.505]: number of params:73540770
[10/03 16:02:06.525]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:02:06.552]: Creating dataset...
[10/03 16:03:31.476]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:03:31.478]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:03:31.492]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:03:31.493]: rank: 0
[10/03 16:03:31.493]: local_rank: None
[10/03 16:03:31.494]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:03:43.387]: number of params:73540770
[10/03 16:03:43.406]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:03:43.433]: Creating dataset...
[10/03 16:05:53.062]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:05:53.064]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:05:53.078]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:05:53.078]: rank: 0
[10/03 16:05:53.078]: local_rank: None
[10/03 16:05:53.079]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:06:05.090]: number of params:73540770
[10/03 16:06:05.109]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:06:05.136]: Creating dataset...
[10/03 16:13:02.205]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:13:02.207]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:13:02.220]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:13:02.221]: rank: 0
[10/03 16:13:02.221]: local_rank: None
[10/03 16:13:02.222]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:13:14.427]: number of params:73540770
[10/03 16:13:14.446]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:13:14.472]: Creating dataset...
[10/03 16:16:17.436]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:16:17.438]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:16:17.452]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:16:17.452]: rank: 0
[10/03 16:16:17.452]: local_rank: None
[10/03 16:16:17.454]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:16:29.347]: number of params:73540770
[10/03 16:16:29.366]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:16:29.393]: Creating dataset...
[10/03 16:18:48.527]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:18:48.529]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:18:48.542]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:18:48.542]: rank: 0
[10/03 16:18:48.542]: local_rank: None
[10/03 16:18:48.543]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:19:01.100]: number of params:73540770
[10/03 16:19:01.131]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:19:01.171]: Creating dataset...
[10/03 16:25:04.816]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:25:04.818]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:25:04.832]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:25:04.832]: rank: 0
[10/03 16:25:04.832]: local_rank: None
[10/03 16:25:04.833]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:25:17.491]: number of params:73540770
[10/03 16:25:17.511]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:25:17.537]: Creating dataset...
[10/03 16:26:34.412]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:26:34.414]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:26:34.428]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:26:34.428]: rank: 0
[10/03 16:26:34.429]: local_rank: None
[10/03 16:26:34.430]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:26:46.700]: number of params:73540770
[10/03 16:26:46.728]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:26:46.767]: Creating dataset...
[10/03 16:29:49.435]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:29:49.437]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:29:49.450]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:29:49.451]: rank: 0
[10/03 16:29:49.451]: local_rank: None
[10/03 16:29:49.452]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:30:01.336]: number of params:73540770
[10/03 16:30:01.355]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:30:01.381]: Creating dataset...
[10/03 16:30:23.933]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:30:23.935]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:30:23.948]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:30:23.948]: rank: 0
[10/03 16:30:23.948]: local_rank: None
[10/03 16:30:23.949]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:30:35.795]: number of params:73540770
[10/03 16:30:35.814]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:30:35.841]: Creating dataset...
[10/03 16:33:50.535]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:33:50.537]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:33:50.552]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:33:50.552]: rank: 0
[10/03 16:33:50.552]: local_rank: None
[10/03 16:33:50.553]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:34:02.758]: number of params:73540770
[10/03 16:34:02.777]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:34:02.804]: Creating dataset...
[10/03 16:37:05.854]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:37:05.856]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:37:05.872]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:37:05.872]: rank: 0
[10/03 16:37:05.872]: local_rank: None
[10/03 16:37:05.874]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:37:17.460]: number of params:73540770
[10/03 16:37:17.479]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:37:17.506]: Creating dataset...
[10/03 16:47:46.556]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:47:46.558]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:47:46.572]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:47:46.573]: rank: 0
[10/03 16:47:46.573]: local_rank: None
[10/03 16:47:46.574]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:47:58.751]: number of params:73540770
[10/03 16:47:58.771]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:47:58.798]: Creating dataset...
[10/03 16:55:24.389]: git:
  sha: 1b6279fee4b62efe1e20f47d0a59403e45822d30, status: has uncommited changes, branch: main

[10/03 16:55:24.391]: Command: main.py -c config/aios_smplx_demo.py --options batch_size=1 backbone=resnet50 num_person=2 threshold=0.1 --resume data/checkpoint/aios_checkpoint.pth --eval --inference --inference_input demo/img_dir_2 --output_dir demo_single/demo_image
[10/03 16:55:24.405]: Full config saved to demo_single/demo_image/config_args_all.json
[10/03 16:55:24.405]: rank: 0
[10/03 16:55:24.406]: local_rank: None
[10/03 16:55:24.407]: args: Namespace(agora_benchmark='na', amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=1, bbox_loss_coef=5.0, bbox_ratio=1.2, body_3d_size=2, body_bbox_loss_coef=5.0, body_giou_loss_coef=2.0, body_model_test={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_model_train={'type': 'smplx', 'keypoint_src': 'smplx', 'num_expression_coeffs': 10, 'num_betas': 10, 'keypoint_dst': 'smplx_137', 'model_path': 'data/body_models/smplx', 'use_pca': False, 'use_face_contour': True}, body_only=True, camera_3d_size=2.5, clip_max_norm=0.1, cls_loss_coef=2.0, cls_no_bias=False, code_dir=None, config_file='config/aios_smplx_demo.py', config_path='config/aios_smplx.py', continue_train=True, cur_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config', data_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../dataset', data_strategy='balance', dataset_list=[], ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dilation=False, dim_feedforward=2048, distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_batch_gt_fuse=False, dn_bbox_coef=0.5, dn_box_noise_scale=0.4, dn_label_coef=0.3, dn_label_noise_ratio=0.5, dn_labelbook_size=100, dn_number=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=False, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, end_epoch=150, epochs=200, eval=True, exp_name='output/exp52/dataset_debug', face_3d_size=0.3, face_bbox_loss_coef=5.0, face_giou_loss_coef=2.0, face_keypoints_loss_coef=10.0, face_oks_loss_coef=4.0, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, focal=(5000, 5000), focal_alpha=0.25, frozen_weights=None, gamma=0.1, giou_loss_coef=2.0, hand_3d_size=0.3, hidden_dim=256, human_model_path='data/body_models', indices_idx_list=[1, 2, 3, 4, 5, 6, 7], inference=True, inference_input='demo/img_dir_2', input_body_shape=(256, 192), input_face_shape=(192, 192), input_hand_shape=(256, 256), interm_loss_coef=1.0, keypoints_loss_coef=10.0, lhand_bbox_loss_coef=5.0, lhand_giou_loss_coef=2.0, lhand_keypoints_loss_coef=10.0, lhand_oks_loss_coef=0.5, local_rank=None, log_dir=None, losses=['smpl_pose', 'smpl_beta', 'smpl_expr', 'smpl_kp2d', 'smpl_kp3d', 'smpl_kp3d_ra', 'labels', 'boxes', 'keypoints'], lr=1.414e-05, lr_backbone=1.414e-06, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[30, 60], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], make_same_len=False, masks=False, match_unstable_error=False, matcher_type='HungarianMatcher', model_dir=None, modelname='aios_smplx', multi_step_lr=True, nheads=8, nms_iou_threshold=-1, no_aug=False, no_interm_box_loss=False, no_mmpose_keypoint_evaluator=True, num_body_points=17, num_box_decoder_layers=2, num_classes=2, num_face_points=6, num_feature_levels=4, num_group=100, num_hand_face_decoder_layers=4, num_hand_points=6, num_patterns=0, num_person=2, num_queries=900, num_select=50, num_workers=0, oks_loss_coef=4.0, onecyclelr=False, options={'batch_size': 1, 'backbone': 'resnet50', 'num_person': 2, 'threshold': 0.1}, output_dir='demo_single/demo_image', output_face_hm_shape=(8, 8, 8), output_hand_hm_shape=(16, 16, 16), output_hm_shape=(16, 16, 12), param_dict_type='default', pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, pretrained_model_path='../output/train_gta_synbody_ft_20230410_132110/model_dump/snapshot_2.pth.tar', princpt=(96.0, 128.0), query_dim=4, random_refpoints_xy=False, rank=0, result_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/../exps62/result', resume='data/checkpoint/aios_checkpoint.pth', return_interm_indices=[1, 2, 3], rhand_bbox_loss_coef=5.0, rhand_giou_loss_coef=2.0, rhand_keypoints_loss_coef=10.0, rhand_oks_loss_coef=0.5, rm_detach=None, rm_self_attn_layers=None, root_dir='/home/dell/DataTool-HumanCentric/detection_aios/AiOS/config/..', save_checkpoint_interval=1, save_log=False, scheduler='step', seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, set_cost_keypoints=10.0, set_cost_kpvis=0.0, set_cost_oks=4.0, smpl_beta_loss_coef=0.01, smpl_body_kp2d_ba_loss_coef=0.0, smpl_body_kp2d_loss_coef=1.0, smpl_body_kp3d_loss_coef=1.0, smpl_body_kp3d_ra_loss_coef=1.0, smpl_expr_loss_coef=0.01, smpl_face_kp2d_ba_loss_coef=0.0, smpl_face_kp2d_loss_coef=0.1, smpl_face_kp3d_loss_coef=0.1, smpl_face_kp3d_ra_loss_coef=0.1, smpl_lhand_kp2d_ba_loss_coef=0.0, smpl_lhand_kp2d_loss_coef=0.5, smpl_lhand_kp3d_loss_coef=0.1, smpl_lhand_kp3d_ra_loss_coef=0.1, smpl_pose_loss_body_coef=0.1, smpl_pose_loss_jaw_coef=0.1, smpl_pose_loss_lhand_coef=0.1, smpl_pose_loss_rhand_coef=0.1, smpl_pose_loss_root_coef=1.0, smpl_rhand_kp2d_ba_loss_coef=0.0, smpl_rhand_kp2d_loss_coef=0.5, smpl_rhand_kp3d_loss_coef=0.1, smpl_rhand_kp3d_ra_loss_coef=0.1, start_epoch=0, step_size=20, strong_aug=False, test=False, test_max_size=1333, test_sample_interval=100, test_sizes=[800], testset='INFERENCE_demo', threshold=0.1, to_vid=False, total_data_len='auto', train_batch_size=32, train_max_size=1333, train_sample_interval=10, train_sizes=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], trainset_2d=[], trainset_3d=[], trainset_humandata=[], trainset_partition={}, transformer_activation='relu', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_type='standard', use_cache=True, use_checkpoint=False, use_dn=True, use_ema=True, vis_dir=None, weight_decay=0.0001)

[10/03 16:55:36.610]: number of params:73540770
[10/03 16:55:36.629]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 34,
  "transformer.decoder.keypoint_embed.weight": 4352,
  "transformer.decoder.lhand_box_embed.weight": 256,
  "transformer.decoder.rhand_box_embed.weight": 256,
  "transformer.decoder.face_box_embed.weight": 256,
  "transformer.decoder.hw_lhand_bbox.weight": 2,
  "transformer.decoder.hw_rhand_bbox.weight": 2,
  "transformer.decoder.hw_face_bbox.weight": 2,
  "transformer.decoder.hw_lhand_kps.weight": 12,
  "transformer.decoder.hw_rhand_kps.weight": 12,
  "transformer.decoder.hw_face_kps.weight": 12,
  "transformer.decoder.lhand_keypoint_embed.weight": 1536,
  "transformer.decoder.rhand_keypoint_embed.weight": 1536,
  "transformer.decoder.face_keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_embed.4.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.0.bias": 256,
  "transformer.decoder.pose_embed.4.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.4.layers.1.bias": 256,
  "transformer.decoder.pose_embed.4.layers.2.weight": 512,
  "transformer.decoder.pose_embed.4.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.decoder.bbox_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_hand_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_hand_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_hand_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_hand_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hand_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hand_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.3.layers.2.bias": 2,
  "transformer.decoder.bbox_face_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_face_embed.4.layers.2.weight": 512,
  "transformer.decoder.bbox_face_embed.4.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.1.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.2.layers.2.bias": 2,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_face_hw_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.weight": 512,
  "transformer.decoder.bbox_face_hw_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_face_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_face_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_face_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_face_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_face_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_face_hw_embed.0.layers.2.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer1.0.conv1.weight": 4096,
  "backbone.0.body.layer1.0.conv2.weight": 36864,
  "backbone.0.body.layer1.0.conv3.weight": 16384,
  "backbone.0.body.layer1.0.downsample.0.weight": 16384,
  "backbone.0.body.layer1.1.conv1.weight": 16384,
  "backbone.0.body.layer1.1.conv2.weight": 36864,
  "backbone.0.body.layer1.1.conv3.weight": 16384,
  "backbone.0.body.layer1.2.conv1.weight": 16384,
  "backbone.0.body.layer1.2.conv2.weight": 36864,
  "backbone.0.body.layer1.2.conv3.weight": 16384,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576,
  "smpl_pose_embed.0.layers.0.weight": 1376256,
  "smpl_pose_embed.0.layers.0.bias": 256,
  "smpl_pose_embed.0.layers.1.weight": 65536,
  "smpl_pose_embed.0.layers.1.bias": 256,
  "smpl_pose_embed.0.layers.2.weight": 33792,
  "smpl_pose_embed.0.layers.2.bias": 132,
  "smpl_pose_embed.1.layers.0.weight": 1376256,
  "smpl_pose_embed.1.layers.0.bias": 256,
  "smpl_pose_embed.1.layers.1.weight": 65536,
  "smpl_pose_embed.1.layers.1.bias": 256,
  "smpl_pose_embed.1.layers.2.weight": 33792,
  "smpl_pose_embed.1.layers.2.bias": 132,
  "smpl_pose_embed.2.layers.0.weight": 1376256,
  "smpl_pose_embed.2.layers.0.bias": 256,
  "smpl_pose_embed.2.layers.1.weight": 65536,
  "smpl_pose_embed.2.layers.1.bias": 256,
  "smpl_pose_embed.2.layers.2.weight": 33792,
  "smpl_pose_embed.2.layers.2.bias": 132,
  "smpl_pose_embed.3.layers.0.weight": 1376256,
  "smpl_pose_embed.3.layers.0.bias": 256,
  "smpl_pose_embed.3.layers.1.weight": 65536,
  "smpl_pose_embed.3.layers.1.bias": 256,
  "smpl_pose_embed.3.layers.2.weight": 33792,
  "smpl_pose_embed.3.layers.2.bias": 132,
  "smpl_beta_embed.0.layers.0.weight": 1376256,
  "smpl_beta_embed.0.layers.0.bias": 256,
  "smpl_beta_embed.0.layers.1.weight": 65536,
  "smpl_beta_embed.0.layers.1.bias": 256,
  "smpl_beta_embed.0.layers.2.weight": 2560,
  "smpl_beta_embed.0.layers.2.bias": 10,
  "smpl_beta_embed.1.layers.0.weight": 1376256,
  "smpl_beta_embed.1.layers.0.bias": 256,
  "smpl_beta_embed.1.layers.1.weight": 65536,
  "smpl_beta_embed.1.layers.1.bias": 256,
  "smpl_beta_embed.1.layers.2.weight": 2560,
  "smpl_beta_embed.1.layers.2.bias": 10,
  "smpl_beta_embed.2.layers.0.weight": 1376256,
  "smpl_beta_embed.2.layers.0.bias": 256,
  "smpl_beta_embed.2.layers.1.weight": 65536,
  "smpl_beta_embed.2.layers.1.bias": 256,
  "smpl_beta_embed.2.layers.2.weight": 2560,
  "smpl_beta_embed.2.layers.2.bias": 10,
  "smpl_beta_embed.3.layers.0.weight": 1376256,
  "smpl_beta_embed.3.layers.0.bias": 256,
  "smpl_beta_embed.3.layers.1.weight": 65536,
  "smpl_beta_embed.3.layers.1.bias": 256,
  "smpl_beta_embed.3.layers.2.weight": 2560,
  "smpl_beta_embed.3.layers.2.bias": 10,
  "smpl_cam_embed.0.layers.0.weight": 1376256,
  "smpl_cam_embed.0.layers.0.bias": 256,
  "smpl_cam_embed.0.layers.1.weight": 65536,
  "smpl_cam_embed.0.layers.1.bias": 256,
  "smpl_cam_embed.0.layers.2.weight": 768,
  "smpl_cam_embed.0.layers.2.bias": 3,
  "smpl_cam_embed.1.layers.0.weight": 1376256,
  "smpl_cam_embed.1.layers.0.bias": 256,
  "smpl_cam_embed.1.layers.1.weight": 65536,
  "smpl_cam_embed.1.layers.1.bias": 256,
  "smpl_cam_embed.1.layers.2.weight": 768,
  "smpl_cam_embed.1.layers.2.bias": 3,
  "smpl_cam_embed.2.layers.0.weight": 1376256,
  "smpl_cam_embed.2.layers.0.bias": 256,
  "smpl_cam_embed.2.layers.1.weight": 65536,
  "smpl_cam_embed.2.layers.1.bias": 256,
  "smpl_cam_embed.2.layers.2.weight": 768,
  "smpl_cam_embed.2.layers.2.bias": 3,
  "smpl_cam_embed.3.layers.0.weight": 1376256,
  "smpl_cam_embed.3.layers.0.bias": 256,
  "smpl_cam_embed.3.layers.1.weight": 65536,
  "smpl_cam_embed.3.layers.1.bias": 256,
  "smpl_cam_embed.3.layers.2.weight": 768,
  "smpl_cam_embed.3.layers.2.bias": 3,
  "smpl_hand_pose_embed.0.layers.0.weight": 65536,
  "smpl_hand_pose_embed.0.layers.0.bias": 256,
  "smpl_hand_pose_embed.0.layers.1.weight": 65536,
  "smpl_hand_pose_embed.0.layers.1.bias": 256,
  "smpl_hand_pose_embed.0.layers.2.weight": 23040,
  "smpl_hand_pose_embed.0.layers.2.bias": 90,
  "smpl_hand_pose_embed.1.layers.0.weight": 65536,
  "smpl_hand_pose_embed.1.layers.0.bias": 256,
  "smpl_hand_pose_embed.1.layers.1.weight": 65536,
  "smpl_hand_pose_embed.1.layers.1.bias": 256,
  "smpl_hand_pose_embed.1.layers.2.weight": 23040,
  "smpl_hand_pose_embed.1.layers.2.bias": 90,
  "smpl_hand_pose_embed.2.layers.0.weight": 589824,
  "smpl_hand_pose_embed.2.layers.0.bias": 256,
  "smpl_hand_pose_embed.2.layers.1.weight": 65536,
  "smpl_hand_pose_embed.2.layers.1.bias": 256,
  "smpl_hand_pose_embed.2.layers.2.weight": 23040,
  "smpl_hand_pose_embed.2.layers.2.bias": 90,
  "smpl_hand_pose_embed.3.layers.0.weight": 589824,
  "smpl_hand_pose_embed.3.layers.0.bias": 256,
  "smpl_hand_pose_embed.3.layers.1.weight": 65536,
  "smpl_hand_pose_embed.3.layers.1.bias": 256,
  "smpl_hand_pose_embed.3.layers.2.weight": 23040,
  "smpl_hand_pose_embed.3.layers.2.bias": 90,
  "smpl_expr_embed.0.layers.0.weight": 65536,
  "smpl_expr_embed.0.layers.0.bias": 256,
  "smpl_expr_embed.0.layers.1.weight": 65536,
  "smpl_expr_embed.0.layers.1.bias": 256,
  "smpl_expr_embed.0.layers.2.weight": 2560,
  "smpl_expr_embed.0.layers.2.bias": 10,
  "smpl_expr_embed.1.layers.0.weight": 65536,
  "smpl_expr_embed.1.layers.0.bias": 256,
  "smpl_expr_embed.1.layers.1.weight": 65536,
  "smpl_expr_embed.1.layers.1.bias": 256,
  "smpl_expr_embed.1.layers.2.weight": 2560,
  "smpl_expr_embed.1.layers.2.bias": 10,
  "smpl_expr_embed.2.layers.0.weight": 524288,
  "smpl_expr_embed.2.layers.0.bias": 256,
  "smpl_expr_embed.2.layers.1.weight": 65536,
  "smpl_expr_embed.2.layers.1.bias": 256,
  "smpl_expr_embed.2.layers.2.weight": 2560,
  "smpl_expr_embed.2.layers.2.bias": 10,
  "smpl_expr_embed.3.layers.0.weight": 524288,
  "smpl_expr_embed.3.layers.0.bias": 256,
  "smpl_expr_embed.3.layers.1.weight": 65536,
  "smpl_expr_embed.3.layers.1.bias": 256,
  "smpl_expr_embed.3.layers.2.weight": 2560,
  "smpl_expr_embed.3.layers.2.bias": 10,
  "smpl_jaw_embed.0.layers.0.weight": 65536,
  "smpl_jaw_embed.0.layers.0.bias": 256,
  "smpl_jaw_embed.0.layers.1.weight": 65536,
  "smpl_jaw_embed.0.layers.1.bias": 256,
  "smpl_jaw_embed.0.layers.2.weight": 1536,
  "smpl_jaw_embed.0.layers.2.bias": 6,
  "smpl_jaw_embed.1.layers.0.weight": 65536,
  "smpl_jaw_embed.1.layers.0.bias": 256,
  "smpl_jaw_embed.1.layers.1.weight": 65536,
  "smpl_jaw_embed.1.layers.1.bias": 256,
  "smpl_jaw_embed.1.layers.2.weight": 1536,
  "smpl_jaw_embed.1.layers.2.bias": 6,
  "smpl_jaw_embed.2.layers.0.weight": 524288,
  "smpl_jaw_embed.2.layers.0.bias": 256,
  "smpl_jaw_embed.2.layers.1.weight": 65536,
  "smpl_jaw_embed.2.layers.1.bias": 256,
  "smpl_jaw_embed.2.layers.2.weight": 1536,
  "smpl_jaw_embed.2.layers.2.bias": 6,
  "smpl_jaw_embed.3.layers.0.weight": 524288,
  "smpl_jaw_embed.3.layers.0.bias": 256,
  "smpl_jaw_embed.3.layers.1.weight": 65536,
  "smpl_jaw_embed.3.layers.1.bias": 256,
  "smpl_jaw_embed.3.layers.2.weight": 1536,
  "smpl_jaw_embed.3.layers.2.bias": 6
}
[10/03 16:55:36.655]: Creating dataset...
